{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Movie Data Analysis\n",
    "\n",
    "## Goal of Analysis: Use machine learning algorithms to get a highly accurate prediction for how popular a movie will be given the attributes in the TMDB 5000 Movies Dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the TMDB 5000 Movies Dataset\n",
    "df = pd.read_csv('tmdb_5000_movies.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a copy of the original DataFrame for cleaning\n",
    "df_clean = df.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['homepage', 'original_title', 'status']\n",
    "df_clean.drop(columns=columns_to_drop, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set the index to the values in the id column for identification purposes\n",
    "df_clean.set_index('id', inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# genres; Extract genre names\n",
    "df_clean['genres'] = df_clean['genres'].apply(lambda x: [genre['name'] for genre in eval(x)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# keywords; Extract keywords\n",
    "df_clean['keywords'] = df_clean['keywords'].apply(lambda x: [keyword['name'] for keyword in eval(x)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# production_companies; Extract production company names\n",
    "df_clean['production_companies'] = df_clean['production_companies'].apply(lambda x: [company['name'] for company in eval(x)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# production_countries; Extract production countries\n",
    "df_clean['production_countries'] = df_clean['production_countries'].apply(lambda x: [country['name'] for country in eval(x)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# release_date; Convert to datetime format\n",
    "df_clean['release_date'] = pd.to_datetime(df_clean['release_date'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# spoken_languages; Extract spoken languages\n",
    "df_clean['spoken_languages'] = df_clean['spoken_languages'].apply(lambda x: [language['name'] for language in eval(x)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# title, overview and tagline; Perform text preprocessing on text data for NLP analysis\n",
    "stop_words = set(stopwords.words('english')) # words that are insignificant\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() # convert characters to lowercase\n",
    "    text = ''.join([char for char in text if char not in string.punctuation]) # remove punctuation\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words]) # remove stop words\n",
    "    return text\n",
    "\n",
    "df_clean['title'] = df_clean['title'].apply(preprocess_text)\n",
    "df_clean['overview'] = df_clean['overview'].apply(preprocess_text)\n",
    "df_clean['tagline'] = df_clean['tagline'].apply(preprocess_text)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Perform log transformation for positively-skewed attributes\n",
    "df_clean['budget'] = np.log1p(df_clean['budget'])\n",
    "df_clean['popularity'] = np.log1p(df_clean['popularity'])\n",
    "df_clean['revenue'] = np.log1p(df_clean['revenue'])\n",
    "df_clean['vote_count'] = np.log1p(df_clean['vote_count'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Account for multicollinearity\n",
    "df_clean.drop('vote_count', axis=1, inplace=True) # vote_count and popularity highly correlated, drop vote_count\n",
    "\n",
    "df_clean['revenue_budget_ratio'] = np.where( # revenue and budget highly correlated, perform feature engineering\n",
    "    (df['budget'] != 0) & (df['revenue'] != 0), # if revenue and budget are both nonzero\n",
    "    df['revenue'] / df['budget'], # calculate the revenue to budget ratio\n",
    "    0  # else, replace with 0\n",
    ")\n",
    "df_clean.drop('revenue', axis=1, inplace=True) # drop the revenue variable\n",
    "df_clean.drop('budget', axis=1, inplace=True) # drop the budget variable\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Encode categorical variables\n",
    "\n",
    "le = preprocessing.LabelEncoder() # initialize LabelEncoder\n",
    "\n",
    "# Perform label encoding for categorical variables\n",
    "df_clean['genres_cat'] = le.fit_transform(df_clean['genres'])\n",
    "df_clean['keywords_cat'] = le.fit_transform(df_clean['keywords'])\n",
    "df_clean['production_companies_cat'] = le.fit_transform(df_clean['production_companies'])\n",
    "df_clean['production_countries_cat'] = le.fit_transform(df_clean['production_countries'])\n",
    "df_clean['spoken_languages_cat'] = le.fit_transform(df_clean['spoken_languages'])\n",
    "\n",
    "# Drop old categorical fields from the dataframe\n",
    "categorical_fields = ['genres', 'keywords', 'production_companies', 'production_countries', 'spoken_languages']\n",
    "data = df_clean.drop(columns=categorical_fields, inplace=True)\n",
    "\n",
    "# Reindex the dataframe with encoded categorical columns and non-categorical columns\n",
    "encoded_columns = ['genres_cat', 'keywords_cat', 'production_companies_cat', 'production_countries_cat', 'spoken_languages_cat']\n",
    "data = df_clean.reindex(encoded_columns + df_clean.columns.difference(encoded_columns).tolist(), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Normalize the continuous variables\n",
    "continuous = ['revenue_budget_ratio', 'popularity', 'runtime', 'vote_average']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for var in continuous:\n",
    "    data[var] = data[var].astype('float64')\n",
    "    data[var] = scaler.fit_transform(data[var].values.reshape(-1, 1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Split data into training and testing sets\n",
    "X = data.drop(columns=['popularity'])  # features\n",
    "y = data['popularity']  # target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Linear Regression Model\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NLP Text Analysis\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "text_variables = ['title', 'overview', 'tagline']\n",
    "X_text = tfidf_vectorizer.fit_transform(data[text_variables]) # vectorize text variables\n",
    "\n",
    "text_model = LinearSVR()\n",
    "text_model.fit(X_text, y_train)  # fit LinearSVR model on text data\n",
    "\n",
    "X_test_text = tfidf_vectorizer.transform(data[text_variables])\n",
    "y_text_pred = text_model.predict(X_test_text)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}